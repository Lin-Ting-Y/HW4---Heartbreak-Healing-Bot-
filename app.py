import os
from pathlib import Path
from shutil import rmtree
import streamlit as st
from dotenv import load_dotenv

# --- LangChain Imports ---
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_google_genai import ChatGoogleGenerativeAI


def load_env():
    load_dotenv()
    api_key = os.getenv("GOOGLE_API_KEY") or st.secrets.get("GOOGLE_API_KEY", "")
    
    if api_key:
        os.environ["GOOGLE_API_KEY"] = api_key
    else:
        st.warning("âš ï¸ ç¼ºå°‘ GOOGLE_API_KEYï¼Œè«‹åœ¨ .env æˆ– Streamlit secrets ä¸­è¨­å®šã€‚", icon="âš ï¸")
    return api_key


def get_vector_store(books_dir: str = "books", cache_dir: str = ".faiss_index") -> FAISS:
    base_path = Path(books_dir)
    if not base_path.exists():
        base_path.mkdir(parents=True, exist_ok=True)

    # å¼·åˆ¶ä½¿ç”¨ CPUï¼Œé¿å…é›²ç«¯éƒ¨ç½²éŒ¯èª¤
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        model_kwargs={"device": "cpu"}
    )

    cache_path = Path(cache_dir)
    if cache_path.exists():
        try:
            return FAISS.load_local(str(cache_path), embeddings, allow_dangerous_deserialization=True)
        except Exception:
            pass

    loader = DirectoryLoader(
        str(base_path),
        glob="**/*.txt",
        loader_cls=TextLoader,
        loader_kwargs={"encoding": "utf-8"},
        show_progress=True,
    )
    docs = loader.load()

    if not docs:
        return None

    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
    chunks = splitter.split_documents(docs)
    
    vector_store = FAISS.from_documents(chunks, embeddings)
    cache_path.mkdir(parents=True, exist_ok=True)
    vector_store.save_local(str(cache_path))
    return vector_store


def build_persona_prompt(context: str) -> str:
    persona = (
        "ä½ æ˜¯ä¸€ä½ã€æš–å¿ƒç™‚ç™’å¸«ã€ï¼Œä¹Ÿæ˜¯ä½¿ç”¨è€…æœ€è¦ªå¯†çš„çŸ¥å¿ƒå¥½å‹ã€‚"
        "ä½ éå¸¸æœ‰è€å¿ƒï¼Œé¡˜æ„èŠ±æ™‚é–“å‚¾è½ï¼Œä¸¦ä¸”æœƒç”¨æº«æŸ”ç´°è†©çš„æ–‡å­—ä¾†åŒ…è¦†ä½¿ç”¨è€…çš„å‚·å£ã€‚"
        "è«‹ä¸è¦æ€¥è‘—çµ¦å‡ºè§£æ±ºæ–¹æ¡ˆï¼Œæœ€é‡è¦çš„æ˜¯è®“ä½¿ç”¨è€…æ„Ÿåˆ°è¢«æ„›èˆ‡è¢«æ¥ç´ã€‚"
    )
    instructions = (
        "å›ç­”æŒ‡å¼•ï¼š\n"
        "1. **åˆ¤æ–·æ„åœ–**ï¼š\n"
        "   - **æ‰“æ‹›å‘¼**ï¼šè«‹å±•ç¾ç†±æƒ…èˆ‡æº«æš–ï¼Œç°¡å–®ä»‹ç´¹è‡ªå·±ï¼Œä¸¦é‚€è«‹å°æ–¹åˆ†äº«å¿ƒäº‹ã€‚\n"
        "   - **å‚¾è¨´ç…©æƒ±**ï¼šè«‹é‹ç”¨ä¸‹æ–¹çš„ã€åƒè€ƒè³‡æ–™ã€‘é€²è¡Œæ·±åº¦çš„å°è©±ã€‚\n"
        "2. **å›æ‡‰é¢¨æ ¼ (é‡è¦)**ï¼š\n"
        "   - **å¤šä¸€é»è©±èª**ï¼šè«‹ä¸è¦å¤ªç°¡çŸ­ï¼Œè©¦è‘—å¤šå¯«å¹¾å¥æº«æš–çš„è©±ï¼Œåƒæ˜¯åœ¨å¯«ä¿¡çµ¦å¥½æœ‹å‹ä¸€æ¨£ã€‚\n"
        "   - **é¿å…èªªæ•™**ï¼šä¸è¦åªçµ¦æ¢åˆ—å¼çš„å»ºè­° (1. 2. 3.)ï¼Œè«‹å°‡å»ºè­°è‡ªç„¶åœ°èå…¥åœ¨å°è©±æ®µè½ä¸­ã€‚\n"
        "   - **æƒ…æ„Ÿé€£çµ**ï¼šå¤šä½¿ç”¨ã€Œæˆ‘æ‡‚ã€ã€ã€Œè¾›è‹¦ä½ äº†ã€ã€ã€Œæ²’é—œä¿‚çš„ã€é€™é¡æ’«æ…°æ€§çš„èªå¥ã€‚\n"
        "   - **å¼•å°å®£æ´©**ï¼šåœ¨çµå°¾å¯ä»¥ç”¨æº«æŸ”çš„å•å¥ï¼Œå¼•å°ä½¿ç”¨è€…å¤šèªªä¸€é»å¿ƒè£¡çš„æ„Ÿå—ã€‚\n"
    )
    return f"{persona}\n\nã€åƒè€ƒè³‡æ–™ (Context)ã€‘:\n{context}\n\n{instructions}"


def main():
    st.set_page_config(page_title="Heartbreak Healing Bot", page_icon="ğŸ’—")
    st.title("ğŸ’— Heartbreak Healing Bot")
    st.subheader("å¤±æˆ€é™£ç·šè¯ç›Ÿé—œå¿ƒä½  æ‹’çµ•æˆ€æ„›è…¦å¤§ä½œæˆ°")
    
    api_key = load_env()

    if "vector_store" not in st.session_state:
        if Path("books").exists() and list(Path("books").glob("*.txt")):
             with st.spinner("æ­£åœ¨é–±è®€ç™‚ç™’æ›¸ç±..."):
                st.session_state.vector_store = get_vector_store("books")
        else:
            st.session_state.vector_store = None

    if "messages" not in st.session_state:
        st.session_state.messages = []

    with st.sidebar:
        st.header("è¨­å®š")
        
        # âœ… é€™è£¡å·²ç¶“è¨­å®š gemini-2.5-flash ç‚ºç¬¬ä¸€å€‹é¸é …ï¼ˆé è¨­å€¼ï¼‰
        model_name = st.selectbox(
            "Gemini æ¨¡å‹",
            options=["gemini-2.5-flash", "gemini-2.0-flash", "gemini-2.5-pro", "gemini-1.5-pro"],
            index=0,
            help="é è¨­ä½¿ç”¨æœ€æ–°çš„ 2.5 Flash æ¨¡å‹ï¼Œé€Ÿåº¦å¿«ä¸”å›æ‡‰å“è³ªé«˜ï¼",
        )
        
        temperature = st.slider(
            "æ„Ÿæ€§ç¨‹åº¦ (Temperature)",
            0.0, 1.0, 0.7, 0.05,
            help="èª¿é«˜æœƒæ›´æº«æš–æ„Ÿæ€§ï¼Œèª¿ä½æœƒæ›´ç†æ€§ã€‚"
        )
        st.caption("ğŸ’¡ æç¤ºï¼šæ•¸å€¼è¶Šé«˜ï¼Œå›æ‡‰è¶Šæº«æš–æ„Ÿæ€§ã€‚")
        
        st.divider()
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ”„ é‡å»ºå¤§è…¦"):
                with st.spinner("æ­£åœ¨é‡æ–°é–±è®€..."):
                    try:
                        if Path(".faiss_index").exists():
                            rmtree(Path(".faiss_index"))
                    except Exception:
                        pass
                    st.session_state.vector_store = get_vector_store("books")
                st.success("å®Œæˆï¼")
        
        with col2:
            if st.button("ğŸ—‘ï¸ æ¸…é™¤å°è©±"):
                st.session_state.messages = []
                st.rerun()

    if not st.session_state.vector_store:
        st.info("ğŸ‘ˆ è«‹åœ¨ `books` è³‡æ–™å¤¾æ”¾å…¥ .txt æ–‡ç« ï¼Œä¸¦é»æ“Šå´é‚Šæ¬„çš„ã€Œé‡å»ºå¤§è…¦ã€ã€‚")
        return

    user_input = st.chat_input("æƒ³èªªä»€éº¼éƒ½å¯ä»¥ï¼Œæˆ‘åœ¨é€™è£¡é™ªä½ ...")

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    if user_input:
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        retriever = st.session_state.vector_store.as_retriever(search_kwargs={"k": 4})
        with st.spinner("æ­£åœ¨å°‹æ‰¾æº«æš–çš„å»ºè­°..."):
            docs = retriever.invoke(user_input)
        
        context_text = "\n\n".join(d.page_content for d in docs)
        
        system_prompt = build_persona_prompt(context_text)

        if not api_key:
            st.error("è«‹è¨­å®š API Keyã€‚")
            return

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_input),
        ]

        with st.chat_message("assistant"):
            with st.spinner("æ­£åœ¨ç”¨å¿ƒæ’°å¯«å›æ‡‰..."):
                try:
                    llm = ChatGoogleGenerativeAI(
                        model=model_name,
                        google_api_key=api_key,
                        temperature=temperature,
                    )
                    response = llm.invoke(messages)
                    reply_text = getattr(response, "content", str(response))
                    
                    st.markdown(reply_text)
                    st.session_state.messages.append({"role": "assistant", "content": reply_text})
                
                except Exception as e:
                    err_msg = str(e)
                    # é‡å°é¡åº¦å•é¡Œçµ¦å‡ºæ›´ç²¾ç¢ºçš„å»ºè­°
                    if "429" in err_msg or "Quota" in err_msg:
                        st.error("ğŸš¨ è©²æ¨¡å‹çš„ä»Šæ—¥é¡åº¦å·²æ»¿ï¼Œè«‹åˆ‡æ›å› gemini-2.0-flash æˆ–å…¶ä»–æ¨¡å‹è©¦è©¦ã€‚")
                    else:
                        st.error(f"ç™¼ç”ŸéŒ¯èª¤: {err_msg}")

if __name__ == "__main__":
    main()
